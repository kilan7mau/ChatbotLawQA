from fastapi import Depends, HTTPException
from schemas.chat import QueryRequest, AnswerResponse, SourceDocument
from schemas.user import UserOut
from dependencies import get_current_user
import time
import json
from utils.utils import save_chat_to_redis, search_term_in_dictionary, minimal_preprocess_for_llm, save_chat_to_mongo, get_langchain_chat_history
import os
import logging
from db.mongoDB import conversations_collection
from datetime import datetime, timezone
import asyncio

logger = logging.getLogger(__name__)


async def ask_question_service(app_state, request: QueryRequest, user: UserOut = Depends(get_current_user)):
    chat_id = request.chat_id
    question_content = request.input # Gi·ªØ l·∫°i c√¢u h·ªèi g·ªëc c·ªßa user ƒë·ªÉ l∆∞u

    # --- 1. X√°c th·ª±c v√† ki·ªÉm tra metadata t·ª´ Redis ---
    meta_key = f"conversation_meta:{chat_id}"
    if not await  app_state.redis.exists(meta_key): # D√πng await n·∫øu redis client l√† async
        logger.warning(f"Metadata cho chat_id {chat_id} kh√¥ng t√¨m th·∫•y trong Redis.")
        raise HTTPException(status_code=404, detail="Chat ID not found or session expired. Please reload the conversation.")

    user_in_redis = await app_state.redis.hget(meta_key, "user_id") # Key ƒë√£ ƒë·ªïi th√†nh user_id
    if not user_in_redis:
        logger.error(f"user_id kh√¥ng c√≥ trong metadata c·ªßa chat {chat_id}.")
        raise HTTPException(status_code=404, detail="Chat metadata corrupted.")

    if user_in_redis != user.email:
        logger.warning(f"User {user.email} kh√¥ng ƒë∆∞·ª£c ph√©p truy c·∫≠p chat {chat_id} (thu·ªôc v·ªÅ {user_in_redis.decode()}).")
        raise HTTPException(status_code=403, detail="Unauthorized to access this chat.")

    start_time = time.time()
    current_utc_time = datetime.now(timezone.utc) # S·ª≠ d·ª•ng UTC cho timestamp

    # --- 2. Ti·ªÅn x·ª≠ l√Ω c√¢u h·ªèi ---
    cleaned_question = minimal_preprocess_for_llm(question_content)

    # --- 3. Ki·ªÉm tra t·ª´ ƒëi·ªÉn thu·∫≠t ng·ªØ (n·∫øu c√≥) ---
    if hasattr(app_state, 'dict') and app_state.dict:
        term_result = search_term_in_dictionary(cleaned_question, app_state.dict)
        if term_result:
            answer_def = term_result.get("definition", "Kh√¥ng th·ªÉ t√¨m th·∫•y ƒë·ªãnh nghƒ©a.")
            assistant_response_time = datetime.now(timezone.utc)

            # L∆∞u v√†o Redis v√† MongoDB
            await save_chat_to_redis(
                app_state.redis, chat_id, question_content, answer_def, current_utc_time, assistant_response_time
            )
            await save_chat_to_mongo(
                conversations_collection, chat_id, user.email, question_content, answer_def, current_utc_time, assistant_response_time
            )
            friendly_answer = f"Xin ch√†o! V·ªÅ c√¢u h·ªèi '{question_content}' c·ªßa b·∫°n, t√¥i ƒë√£ t√¨m th·∫•y th√¥ng tin sau:\n\n{answer_def}\n\nHy v·ªçng th√¥ng tin n√†y h·ªØu √≠ch cho b·∫°n. B·∫°n c√≥ mu·ªën t√¨m hi·ªÉu th√™m v·ªÅ ch·ªß ƒë·ªÅ n√†y ho·∫∑c c√≥ c√¢u h·ªèi n√†o kh√°c kh√¥ng? üòä"
            return AnswerResponse(
                answer=friendly_answer,
                sources=[
                    SourceDocument(
                        source="Thu·∫≠t ng·ªØ ph√°p l√Ω",
                        page_content_preview=f"ƒê·ªãnh nghƒ©a thu·∫≠t ng·ªØ t·ª´ c∆° s·ªü d·ªØ li·ªáu"
                    )
                ],
                processing_time=round(time.time() - start_time, 2)
            )

    if not app_state.qa_chain:
        logger.error("QA Chain ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o.")
        raise HTTPException(status_code=503, detail="Service Unavailable: QA Chain not ready.")


    try:
        redis_url = os.environ.get("REDIS_URL_LANGCHAIN", os.environ.get("REDIS_URL")) # ∆Øu ti√™n URL ri√™ng cho Langchain n·∫øu c√≥
        if not redis_url:
            logger.error("REDIS_URL or REDIS_URL_LANGCHAIN not set for RedisChatMessageHistory.")
            raise ValueError("Redis URL for chat history is required.")


        chat_history_messages = await prepare_chat_history_optimized(
            app_state.redis,
            chat_id,
            max_messages=10
        )

        chat_history_string = format_chat_history_for_prompt(chat_history_messages)

        input_data_for_chain = {
            # "chat_history":  langchain_chat_history.messages, # L·∫•y messages ƒë√£ ƒë∆∞·ª£c ƒë·ªìng b·ªô
            "chat_history":  chat_history_string, # L·∫•y messages ƒë√£ ƒë∆∞·ª£c ƒë·ªìng b·ªô
            "input": cleaned_question
        }

    except Exception as e:
        logger.error(f"L·ªói khi chu·∫©n b·ªã chat history cho Langchain (chat_id: {chat_id}): {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="L·ªói x·ª≠ l√Ω l·ªãch s·ª≠ chat.")


    # --- 5. G·ªçi QA Chain ---
    try:
        logger.debug(f"Input to QA Chain (chat_id: {chat_id}): {input_data_for_chain}")

        # Metadata cho LangSmith trace
        langsmith_metadata = {
            "user_email": user.email,
            "chat_id": chat_id,
            "original_question": question_content,
            "cleaned_question": cleaned_question,
            "request_id": request.request_id if hasattr(request, 'request_id') else "N/A" # N·∫øu b·∫°n c√≥ request ID
        }

        chain_result =  app_state.qa_chain.invoke(input_data_for_chain, config={
                    "metadata": langsmith_metadata,
                    "run_name": f"AskService_QA_Invoke_ChatID_{chat_id[:8]}"
                    # "tags": ["production", "qa_service"]
                })

        # logger.info(f"QA Chain raw result (chat_id: {chat_id}): {chain_result}")

        # X·ª≠ l√Ω k·∫øt qu·∫£ t·ª´ chain (logic c·ªßa b·∫°n ƒë·ªÉ tr√≠ch xu·∫•t c√¢u tr·∫£ l·ªùi)
        assistant_response_content = ""
        if isinstance(chain_result, dict) and "answer" in chain_result:
            assistant_response_content = str(chain_result["answer"])
        elif isinstance(chain_result, str): # M·ªôt s·ªë chain c√≥ th·ªÉ tr·∫£ v·ªÅ string tr·ª±c ti·∫øp
            assistant_response_content = chain_result
        else:
            logger.error(f"QA Chain result kh√¥ng h·ª£p l·ªá (chat_id: {chat_id}): {chain_result}")
            assistant_response_content = "Xin l·ªói, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu n√†y v√†o l√∫c n√†y."
            # Kh√¥ng raise l·ªói ·ªü ƒë√¢y ngay, m√† tr·∫£ v·ªÅ th√¥ng b√°o l·ªói cho user v√† log l·∫°i.

        if not assistant_response_content.strip():
             assistant_response_content = "T√¥i kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi ph√π h·ª£p."


    except Exception as chain_error:
        logger.error(f"L·ªói QA Chain (chat_id: {chat_id}): {chain_error}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω t·ª´ QA chain: {str(chain_error)[:100]}")

    assistant_response_time = datetime.now(timezone.utc)

    # --- 6. L∆∞u tin nh·∫Øn m·ªõi (c√¢u h·ªèi c·ªßa user v√† tr·∫£ l·ªùi c·ªßa AI) ---
    # L∆∞u v√†o key "conversation_messages:{chat_id}" c·ªßa ch√∫ng ta
    await save_chat_to_redis(
        app_state.redis, chat_id, question_content, assistant_response_content, current_utc_time, assistant_response_time
    )
    # L∆∞u v√†o MongoDB
    # Ch·∫°y ng·∫ßm ho·∫∑c sau khi tr·∫£ l·ªùi user ƒë·ªÉ kh√¥ng l√†m ch·∫≠m response (n·∫øu c√≥ th·ªÉ)
    await save_chat_to_mongo(
        conversations_collection, chat_id, user.email, question_content, assistant_response_content, current_utc_time, assistant_response_time
    )

    end_time = time.time()

    logger.info(f"Tr·∫£ l·ªùi cho chat {chat_id} b·ªüi user {user.email}: {assistant_response_content[:100]}...")
    return AnswerResponse(
        answer=assistant_response_content,
        processing_time=round(end_time - start_time, 2)
    )

async def stream_chat_generator(
    app_state,
    chat_id: str,
    question_content: str,
    user_email: str
):
    """
    Generator function to stream chat responses.
    Yields data in Server-Sent Events (SSE) format.
    """
    start_time_total = time.time()
    current_utc_time = datetime.now(timezone.utc)
    full_answer_for_saving = "" # ƒê·ªÉ l∆∞u to√†n b·ªô c√¢u tr·∫£ l·ªùi v√†o DB

    try:
        # --- 1. X√°c th·ª±c v√† ki·ªÉm tra metadata t·ª´ Redis (T∆∞∆°ng t·ª± ask_question_service) ---
        meta_key = f"conversation_meta:{chat_id}"
        if not  app_state.redis.exists(meta_key):
            logger.warning(f"Stream: Metadata cho chat_id {chat_id} kh√¥ng t√¨m th·∫•y.")
            error_payload = {"error": "Chat ID not found or session expired. Please reload."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        user_in_redis_bytes =  app_state.redis.hget(meta_key, "user_id")
        if not user_in_redis_bytes:
            logger.error(f"Stream: user_id kh√¥ng c√≥ trong metadata c·ªßa chat {chat_id}.")
            error_payload = {"error": "Chat metadata corrupted."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        user_in_redis = user_in_redis_bytes.decode()
        if user_in_redis != user_email:
            logger.warning(f"Stream: User {user_email} kh√¥ng ƒë∆∞·ª£c ph√©p truy c·∫≠p chat {chat_id}.")
            error_payload = {"error": "Unauthorized to access this chat."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        # --- 2. Ti·ªÅn x·ª≠ l√Ω c√¢u h·ªèi (T∆∞∆°ng t·ª±) ---
        cleaned_question = minimal_preprocess_for_llm(question_content)

        initial_processing_done_time = time.time()
        logger.info(f"Stream: Initial processing for {chat_id} took {initial_processing_done_time - start_time_total:.2f}s")

        # --- 3. Ki·ªÉm tra t·ª´ ƒëi·ªÉn thu·∫≠t ng·ªØ (n·∫øu c√≥, v√† n√≥ nhanh) ---
        if hasattr(app_state, 'dict') and app_state.dict:
            term_result = search_term_in_dictionary(cleaned_question, app_state.dict)
            if term_result:
                answer_def = term_result.get("definition", "Kh√¥ng th·ªÉ t√¨m th·∫•y ƒë·ªãnh nghƒ©a.")
                assistant_response_time_dict = datetime.now(timezone.utc)
                full_answer_for_saving = answer_def # G√°n cho l∆∞u tr·ªØ

                # Stream to√†n b·ªô ƒë·ªãnh nghƒ©a nh∆∞ m·ªôt chunk
                data_payload = {"token": answer_def, "is_final": True, "source": "dictionary"}
                yield f"data: {json.dumps(data_payload)}\n\n"
                # C√≥ th·ªÉ g·ª≠i event k·∫øt th√∫c ri√™ng
                yield f"event: end_stream\ndata: {{}}\n\n" # Event k·∫øt th√∫c t√πy ch·ªânh

                # L∆∞u v√†o Redis v√† MongoDB (sau khi stream)
                await save_chat_to_redis(
                    app_state.redis, chat_id, question_content, full_answer_for_saving, current_utc_time, assistant_response_time_dict
                )
                asyncio.create_task(save_chat_to_mongo( # Ch·∫°y n·ªÅn
                    conversations_collection, chat_id, user_email, question_content, full_answer_for_saving, current_utc_time, assistant_response_time_dict
                ))
                processing_time_dict = round(time.time() - start_time_total, 2)
                logger.info(f"Stream: Dictionary answer for {chat_id} sent in {processing_time_dict:.2f}s.")
                return # K·∫øt th√∫c generator ·ªü ƒë√¢y

        if not app_state.qa_chain: # qa_chain ph·∫£i h·ªó tr·ª£ streaming
            logger.error("Stream: QA Chain ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o ho·∫∑c kh√¥ng h·ªó tr·ª£ streaming.")
            error_payload = {"error": "Service Unavailable: QA Chain not ready for streaming."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        # --- 4. L·∫•y l·ªãch s·ª≠ chat cho Langchain Chain (T∆∞∆°ng t·ª±) ---
        try:
            langchain_chat_history = await  get_langchain_chat_history(app_state, chat_id)
            input_data_for_chain = {
                "chat_history": langchain_chat_history.messages,
                "input": cleaned_question
            }
        except Exception as e:
            logger.error(f"Stream: L·ªói khi chu·∫©n b·ªã chat history (chat_id: {chat_id}): {e}", exc_info=True)
            error_payload = {"error": "Error processing chat history."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        # --- 5. G·ªçi QA Chain v·ªõi streaming ---

        if not (hasattr(app_state.qa_chain, 'astream') or hasattr(app_state.qa_chain, 'stream')):
            logger.error(f"Stream: QA Chain (type: {type(app_state.qa_chain)}) kh√¥ng c√≥ ph∆∞∆°ng th·ª©c astream ho·∫∑c stream.")
            error_payload = {"error": "QA Chain does not support streaming."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        chain_stream_method = app_state.qa_chain.astream if hasattr(app_state.qa_chain, 'astream') else app_state.qa_chain.stream

        logger.info(f"Stream: Invoking chain stream for {chat_id}...")
        stream_start_time = time.time()
        chunk_count = 0
        sources_streamed = False # C·ªù ƒë·ªÉ ch·ªâ stream sources m·ªôt l·∫ßn

        async for chunk in chain_stream_method(input_data_for_chain):

            token = ""
            current_sources = None

            if isinstance(chunk, str):
                token = chunk
            elif hasattr(chunk, 'content'): # Gi·ªëng AIMessageChunk
                token = chunk.content
            elif isinstance(chunk, dict):
                token = chunk.get("answer") or chunk.get("token") or chunk.get("content") or ""
                # Ki·ªÉm tra sources n·∫øu chunk l√† dict v√† ch∆∞a stream sources
                if not sources_streamed and "source" in chunk:
                    current_sources = chunk["source"]

            if token:
                full_answer_for_saving += token
                data_payload = {"token": token, "is_final": False}
                yield f"data: {json.dumps(data_payload)}\n\n"
                chunk_count += 1

            # Stream sources n·∫øu c√≥ v√† ch∆∞a ƒë∆∞·ª£c stream
            if current_sources and not sources_streamed:
                sources_list = []
                for doc in current_sources:
                    if hasattr(doc, 'metadata') and hasattr(doc, 'page_content'):
                        sources_list.append(SourceDocument(
                            source=doc.metadata.get('source', 'N/A'),
                            page_content_preview=doc.page_content[:200] + "..."
                        ).dict()) # Chuy·ªÉn sang dict ƒë·ªÉ JSON serialize
                if sources_list:
                    source_payload = {"sources": sources_list}
                    yield f"event: sources\ndata: {json.dumps(source_payload)}\n\n" # Event ri√™ng cho sources
                    sources_streamed = True # ƒê√°nh d·∫•u ƒë√£ stream


        stream_end_time = time.time()
        logger.info(f"Stream: Chain streaming for {chat_id} completed in {stream_end_time - stream_start_time:.2f}s with {chunk_count} chunks.")

        # --- G·ª≠i event k·∫øt th√∫c stream ---
        # Frontend c√≥ th·ªÉ d√πng event n√†y ƒë·ªÉ bi·∫øt stream ƒë√£ ho√†n t·∫•t.
        # Ho·∫∑c, frontend c√≥ th·ªÉ d·ª±a v√†o m·ªôt chunk ƒë·∫∑c bi·ªát nh∆∞ `{"is_final": true}`
        # Ho·∫∑c ƒë∆°n gi·∫£n l√† khi `EventSource.onmessage` kh√¥ng nh·∫≠n ƒë∆∞·ª£c g√¨ n·ªØa sau m·ªôt timeout.
        yield f"event: end_stream\ndata: {{ \"message\": \"Stream ended\" }}\n\n"


        # --- 6. L∆∞u tin nh·∫Øn ho√†n ch·ªânh (sau khi stream xong) ---
        assistant_response_time = datetime.now(timezone.utc)
        if not full_answer_for_saving.strip() and chunk_count == 0: # N·∫øu kh√¥ng c√≥ token n√†o ƒë∆∞·ª£c stream
            full_answer_for_saving = "T√¥i kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi ph√π h·ª£p."
            # Stream c√¢u tr·∫£ l·ªùi m·∫∑c ƒë·ªãnh n√†y n·∫øu ch∆∞a c√≥ g√¨
            data_payload = {"token": full_answer_for_saving, "is_final": True}
            yield f"data: {json.dumps(data_payload)}\n\n"
            yield f"event: end_stream\ndata: {{ \"message\": \"Stream ended with default message\" }}\n\n"


        logger.info(f"Stream: Full answer for {chat_id} to be saved: {full_answer_for_saving[:100]}...")
        await save_chat_to_redis(
            app_state.redis, chat_id, question_content, full_answer_for_saving, current_utc_time, assistant_response_time
        )
        # Ch·∫°y l∆∞u MongoDB ng·∫ßm ƒë·ªÉ kh√¥ng block
        asyncio.create_task(save_chat_to_mongo(
            conversations_collection, chat_id, user_email, question_content, full_answer_for_saving, current_utc_time, assistant_response_time
        ))

        # C·∫≠p nh·∫≠t Langchain history (n·∫øu chain memory kh√¥ng t·ª± l√†m)
        # await langchain_chat_history.aadd_user_message(question_for_chain)
        # await langchain_chat_history.aadd_ai_message(full_answer_for_saving)


    except HTTPException as e: # B·∫Øt HTTPException ƒë√£ ƒë∆∞·ª£c raise t·ª´ c√°c h√†m con
        logger.error(f"Stream: HTTPException for chat_id {chat_id}: {e.detail}", exc_info=True)
        error_payload = {"error": e.detail, "status_code": e.status_code}
        yield f"event: error_stream\ndata: {json.dumps(error_payload)}\n\n"
    except Exception as e:
        logger.error(f"Stream: Unhandled exception for chat_id {chat_id}: {e}", exc_info=True)
        error_payload = {"error": "An unexpected server error occurred during streaming."}
        yield f"event: error_stream\ndata: {json.dumps(error_payload)}\n\n"
    finally:
        # ƒê·∫£m b·∫£o generator k·∫øt th√∫c ƒë√∫ng c√°ch.
        # EventSource tr√™n client s·∫Ω t·ª± ƒë·ªông ƒë√≥ng khi generator k·∫øt th√∫c.
        # Ho·∫∑c b·∫°n c√≥ th·ªÉ g·ª≠i m·ªôt t√≠n hi·ªáu ƒë√≥ng r√µ r√†ng n·∫øu c·∫ßn.
        # yield "event: close\ndata: Connection closed by server\n\n" # Kh√¥ng chu·∫©n SSE, nh∆∞ng m·ªôt s·ªë client c√≥ th·ªÉ hi·ªÉu
        logger.info(f"Stream: Generator for chat_id {chat_id} finished. Total time: {time.time() - start_time_total:.2f}s")


# S·ª≠ d·ª•ng GET cho EventSource theo chu·∫©n, truy·ªÅn params qua query string
# EventSource ch·ªâ h·ªó tr·ª£ GET. N·∫øu b·∫°n B·∫ÆT BU·ªòC ph·∫£i d√πng POST (v√≠ d·ª•, c√¢u h·ªèi qu√° d√†i cho URL),
# b·∫°n s·∫Ω c·∫ßn m·ªôt gi·∫£i ph√°p ph·ª©c t·∫°p h∆°n, kh√¥ng d√πng EventSource tr·ª±c ti·∫øp tr√™n client
# m√† d√πng fetch API v·ªõi ReadableStream v√† POST.


#helper

from typing import List, Optional,Any

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
async def prepare_chat_history_optimized(
    redis:Any,
    chat_id: str,
    max_messages: int = 10,  # S·ªë l∆∞·ª£ng c·∫∑p tin nh·∫Øn (user+AI) t·ªëi ƒëa ƒë·ªÉ l·∫•y
    max_tokens: Optional[int] = None, # (T√πy ch·ªçn n√¢ng cao) Gi·ªõi h·∫°n token
    tokenizer: Optional[Any] = None # (T√πy ch·ªçn n√¢ng cao) Tokenizer ƒë·ªÉ ƒë·∫øm token
) -> List[BaseMessage]:
    """
    C·∫¢I TI·∫æN: L·∫•y N tin nh·∫Øn g·∫ßn nh·∫•t t·ª´ Redis ƒë·ªÉ l√†m l·ªãch s·ª≠ chat.
    - Hi·ªáu qu·∫£ h∆°n b·∫±ng c√°ch ch·ªâ l·∫•y m·ªôt ph·∫ßn l·ªãch s·ª≠.
    - An to√†n h∆°n b·∫±ng c√°ch ki·ªÉm so√°t ƒë·ªô d√†i ng·ªØ c·∫£nh.

    Args:
        redis: Client Redis b·∫•t ƒë·ªìng b·ªô.
        chat_id: ID c·ªßa cu·ªôc tr√≤ chuy·ªán.
        max_messages: S·ªë l∆∞·ª£ng tin nh·∫Øn t·ªëi ƒëa ƒë·ªÉ l·∫•y t·ª´ cu·ªëi (v√≠ d·ª•: 10 tin nh·∫Øn g·∫ßn nh·∫•t).
        max_tokens: (N√¢ng cao) Gi·ªõi h·∫°n t·ªïng s·ªë token c·ªßa l·ªãch s·ª≠.
        tokenizer: (N√¢ng cao) Tokenizer ƒë·ªÉ s·ª≠ d·ª•ng v·ªõi max_tokens.

    Returns:
        M·ªôt danh s√°ch c√°c ƒë·ªëi t∆∞·ª£ng tin nh·∫Øn c·ªßa LangChain (HumanMessage, AIMessage).
    """
    messages_key = f"conversation_messages:{chat_id}"

    # 1. L·∫•y N tin nh·∫Øn g·∫ßn nh·∫•t t·ª´ Redis
    # lrange(key, -N, -1) s·∫Ω l·∫•y N ph·∫ßn t·ª≠ cu·ªëi c√πng c·ªßa list.
    # L·∫•y nhi·ªÅu h∆°n m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ c·∫∑p user/ai ho√†n ch·ªânh.
    num_to_fetch = max_messages + 2
    try:
        # S·ª≠ d·ª•ng lrange ƒë·ªÉ l·∫•y c√°c tin nh·∫Øn g·∫ßn nh·∫•t, hi·ªáu qu·∫£ h∆°n nhi·ªÅu so v·ªõi l·∫•y t·∫•t c·∫£
        raw_messages_json = await redis.lrange(messages_key, -num_to_fetch, -1)
        if not raw_messages_json:
            return []
    except Exception as e:
        logger.error(f"L·ªói khi ƒë·ªçc l·ªãch s·ª≠ chat t·ª´ Redis cho chat_id {chat_id}: {e}")
        return []

    # 2. X√¢y d·ª±ng danh s√°ch tin nh·∫Øn cho LangChain
    langchain_messages: List[BaseMessage] = []
    total_tokens = 0

    # L·∫∑p ng∆∞·ª£c t·ª´ cu·ªëi (tin nh·∫Øn m·ªõi nh·∫•t) ƒë·ªÉ x·ª≠ l√Ω
    for msg_json_str in reversed(raw_messages_json):
        try:
            msg_data = json.loads(msg_json_str)
            content = msg_data.get("content", "")

            # (T√πy ch·ªçn n√¢ng cao) Ki·ªÉm tra gi·ªõi h·∫°n token
            if max_tokens and tokenizer:
                num_tokens = len(tokenizer.encode(content))
                if total_tokens + num_tokens > max_tokens:
                    logger.warning(f"ƒê√£ ƒë·∫°t gi·ªõi h·∫°n token ({max_tokens}) cho l·ªãch s·ª≠ chat. D·ª´ng l·∫°i.")
                    break # D·ª´ng th√™m tin nh·∫Øn
                total_tokens += num_tokens

            # T·∫°o ƒë·ªëi t∆∞·ª£ng tin nh·∫Øn ph√π h·ª£p
            if msg_data.get("role") == "user":
                langchain_messages.append(HumanMessage(content=content))
            elif msg_data.get("role") == "assistant":
                langchain_messages.append(AIMessage(content=content))

        except (json.JSONDecodeError, KeyError) as e:
            logger.warning(f"L·ªói khi parse tin nh·∫Øn t·ª´ Redis: {e}. B·ªè qua tin nh·∫Øn n√†y.")
            continue

    # 3. ƒê·∫£o ng∆∞·ª£c l·∫°i danh s√°ch ƒë·ªÉ c√≥ ƒë√∫ng th·ª© t·ª± (c≈© -> m·ªõi)
    langchain_messages.reverse()

    # C·∫Øt l·∫°i theo max_messages cu·ªëi c√πng ƒë·ªÉ ƒë·∫£m b·∫£o s·ªë l∆∞·ª£ng ch√≠nh x√°c
    return langchain_messages[-max_messages:]

def format_chat_history_for_prompt(chat_history: List[BaseMessage]) -> str:
    """
    Chuy·ªÉn ƒë·ªïi danh s√°ch ƒë·ªëi t∆∞·ª£ng tin nh·∫Øn th√†nh m·ªôt chu·ªói vƒÉn b·∫£n duy nh·∫•t.
    """
    if not chat_history:
        return "Kh√¥ng c√≥ l·ªãch s·ª≠ tr√≤ chuy·ªán."

    formatted_history = []
    for message in chat_history:
        role = "Ng∆∞·ªùi d√πng" if isinstance(message, HumanMessage) else "Tr·ª£ l√Ω"
        formatted_history.append(f"{role}: {message.content}")

    return "\n".join(formatted_history)