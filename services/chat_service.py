from fastapi import Depends, HTTPException
from schemas.chat import QueryRequest, AnswerResponse, SourceDocument
from schemas.user import UserOut
from dependencies import get_current_user
import time
import json
from utils.utils import save_chat_to_redis, search_term_in_dictionary, minimal_preprocess_for_llm, save_chat_to_mongo, get_langchain_chat_history
import os
import logging
from db.mongoDB import conversations_collection
from datetime import datetime, timezone
import asyncio

logger = logging.getLogger(__name__)


async def ask_question_service(app_state, request: QueryRequest, user: UserOut = Depends(get_current_user)):
    chat_id = request.chat_id
    question_content = request.input # Giá»¯ láº¡i cÃ¢u há»i gá»‘c cá»§a user Ä‘á»ƒ lÆ°u

    # --- 1. XÃ¡c thá»±c vÃ  kiá»ƒm tra metadata tá»« Redis ---
    meta_key = f"conversation_meta:{chat_id}"
    if not await  app_state.redis.exists(meta_key): # DÃ¹ng await náº¿u redis client lÃ  async
        logger.warning(f"Metadata cho chat_id {chat_id} khÃ´ng tÃ¬m tháº¥y trong Redis.")
        raise HTTPException(status_code=404, detail="Chat ID not found or session expired. Please reload the conversation.")

    user_in_redis = await app_state.redis.hget(meta_key, "user_id") # Key Ä‘Ã£ Ä‘á»•i thÃ nh user_id
    if not user_in_redis:
        logger.error(f"user_id khÃ´ng cÃ³ trong metadata cá»§a chat {chat_id}.")
        raise HTTPException(status_code=404, detail="Chat metadata corrupted.")

    if user_in_redis != user.email:
        logger.warning(f"User {user.email} khÃ´ng Ä‘Æ°á»£c phÃ©p truy cáº­p chat {chat_id} (thuá»™c vá» {user_in_redis.decode()}).")
        raise HTTPException(status_code=403, detail="Unauthorized to access this chat.")

    start_time = time.time()
    current_utc_time = datetime.now(timezone.utc) # Sá»­ dá»¥ng UTC cho timestamp

    # --- 2. Tiá»n xá»­ lÃ½ cÃ¢u há»i ---
    cleaned_question = minimal_preprocess_for_llm(question_content)

    # --- 3. Kiá»ƒm tra tá»« Ä‘iá»ƒn thuáº­t ngá»¯ (náº¿u cÃ³) ---
    if hasattr(app_state, 'dict') and app_state.dict:
        term_result = search_term_in_dictionary(cleaned_question, app_state.dict)
        if term_result:
            answer_def = term_result.get("definition", "KhÃ´ng thá»ƒ tÃ¬m tháº¥y Ä‘á»‹nh nghÄ©a.")
            assistant_response_time = datetime.now(timezone.utc)

            # LÆ°u vÃ o Redis vÃ  MongoDB
            await save_chat_to_redis(
                app_state.redis, chat_id, question_content, answer_def, current_utc_time, assistant_response_time
            )
            await save_chat_to_mongo(
                conversations_collection, chat_id, user.email, question_content, answer_def, current_utc_time, assistant_response_time
            )
            friendly_answer = f"Xin chÃ o! Vá» cÃ¢u há»i '{question_content}' cá»§a báº¡n, tÃ´i Ä‘Ã£ tÃ¬m tháº¥y thÃ´ng tin sau:\n\n{answer_def}\n\nHy vá»ng thÃ´ng tin nÃ y há»¯u Ã­ch cho báº¡n. Báº¡n cÃ³ muá»‘n tÃ¬m hiá»ƒu thÃªm vá» chá»§ Ä‘á» nÃ y hoáº·c cÃ³ cÃ¢u há»i nÃ o khÃ¡c khÃ´ng? ğŸ˜Š"
            return AnswerResponse(
                answer=friendly_answer,
                sources=[
                    SourceDocument(
                        source="Thuáº­t ngá»¯ phÃ¡p lÃ½",
                        page_content_preview=f"Äá»‹nh nghÄ©a thuáº­t ngá»¯ tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u"
                    )
                ],
                processing_time=round(time.time() - start_time, 2)
            )

    if not app_state.qa_chain:
        logger.error("QA Chain chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o.")
        raise HTTPException(status_code=503, detail="Service Unavailable: QA Chain not ready.")


    try:
        redis_url = os.environ.get("REDIS_URL_LANGCHAIN", os.environ.get("REDIS_URL")) # Æ¯u tiÃªn URL riÃªng cho Langchain náº¿u cÃ³
        if not redis_url:
            logger.error("REDIS_URL or REDIS_URL_LANGCHAIN not set for RedisChatMessageHistory.")
            raise ValueError("Redis URL for chat history is required.")


        chat_history_messages = await prepare_chat_history_optimized(
            app_state.redis,
            chat_id,
            max_messages=10
        )

        chat_history_string = format_chat_history_for_prompt(chat_history_messages)

        input_data_for_chain = {
            # "chat_history":  langchain_chat_history.messages, # Láº¥y messages Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»“ng bá»™
            "chat_history":  chat_history_string, # Láº¥y messages Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»“ng bá»™
            "input": cleaned_question
        }

    except Exception as e:
        logger.error(f"Lá»—i khi chuáº©n bá»‹ chat history cho Langchain (chat_id: {chat_id}): {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Lá»—i xá»­ lÃ½ lá»‹ch sá»­ chat.")


    # --- 5. Gá»i QA Chain ---
    try:
        logger.debug(f"Input to QA Chain (chat_id: {chat_id}): {input_data_for_chain}")

        # Metadata cho LangSmith trace
        langsmith_metadata = {
            "user_email": user.email,
            "chat_id": chat_id,
            "original_question": question_content,
            "cleaned_question": cleaned_question,
            "request_id": request.request_id if hasattr(request, 'request_id') else "N/A" # Náº¿u báº¡n cÃ³ request ID
        }

        chain_result =  app_state.qa_chain.invoke(input_data_for_chain, config={
                    "metadata": langsmith_metadata,
                    "run_name": f"AskService_QA_Invoke_ChatID_{chat_id[:8]}"
                    # "tags": ["production", "qa_service"]
                })

        # logger.info(f"QA Chain raw result (chat_id: {chat_id}): {chain_result}")

        # Xá»­ lÃ½ káº¿t quáº£ tá»« chain (logic cá»§a báº¡n Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¢u tráº£ lá»i)
        assistant_response_content = ""
        if isinstance(chain_result, dict) and "answer" in chain_result:
            assistant_response_content = str(chain_result["answer"])
        elif isinstance(chain_result, str): # Má»™t sá»‘ chain cÃ³ thá»ƒ tráº£ vá» string trá»±c tiáº¿p
            assistant_response_content = chain_result
        else:
            logger.error(f"QA Chain result khÃ´ng há»£p lá»‡ (chat_id: {chat_id}): {chain_result}")
            assistant_response_content = "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ xá»­ lÃ½ yÃªu cáº§u nÃ y vÃ o lÃºc nÃ y."
            # KhÃ´ng raise lá»—i á»Ÿ Ä‘Ã¢y ngay, mÃ  tráº£ vá» thÃ´ng bÃ¡o lá»—i cho user vÃ  log láº¡i.

        if not assistant_response_content.strip():
             assistant_response_content = "TÃ´i khÃ´ng tÃ¬m tháº¥y cÃ¢u tráº£ lá»i phÃ¹ há»£p."


    except Exception as chain_error:
        logger.error(f"Lá»—i QA Chain (chat_id: {chat_id}): {chain_error}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Lá»—i xá»­ lÃ½ tá»« QA chain: {str(chain_error)[:100]}")

    assistant_response_time = datetime.now(timezone.utc)

    # --- 6. LÆ°u tin nháº¯n má»›i (cÃ¢u há»i cá»§a user vÃ  tráº£ lá»i cá»§a AI) ---
    # LÆ°u vÃ o key "conversation_messages:{chat_id}" cá»§a chÃºng ta
    await save_chat_to_redis(
        app_state.redis, chat_id, question_content, assistant_response_content, current_utc_time, assistant_response_time
    )
    # LÆ°u vÃ o MongoDB
    # Cháº¡y ngáº§m hoáº·c sau khi tráº£ lá»i user Ä‘á»ƒ khÃ´ng lÃ m cháº­m response (náº¿u cÃ³ thá»ƒ)
    await save_chat_to_mongo(
        conversations_collection, chat_id, user.email, question_content, assistant_response_content, current_utc_time, assistant_response_time
    )

    end_time = time.time()

    logger.info(f"Tráº£ lá»i cho chat {chat_id} bá»Ÿi user {user.email}: {assistant_response_content[:100]}...")
    return AnswerResponse(
        answer=assistant_response_content,
        processing_time=round(end_time - start_time, 2)
    )

async def stream_chat_generator(
    app_state,
    chat_id: str,
    question_content: str,
    user_email: str
):
    """
    Generator function to stream chat responses.
    Yields data in Server-Sent Events (SSE) format.
    """
    start_time_total = time.time()
    current_utc_time = datetime.now(timezone.utc)
    full_answer_for_saving = "" # Äá»ƒ lÆ°u toÃ n bá»™ cÃ¢u tráº£ lá»i vÃ o DB

    try:
        # --- 1. XÃ¡c thá»±c vÃ  kiá»ƒm tra metadata tá»« Redis (TÆ°Æ¡ng tá»± ask_question_service) ---
        meta_key = f"conversation_meta:{chat_id}"
        if not  app_state.redis.exists(meta_key):
            logger.warning(f"Stream: Metadata cho chat_id {chat_id} khÃ´ng tÃ¬m tháº¥y.")
            error_payload = {"error": "Chat ID not found or session expired. Please reload."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        user_in_redis_bytes =  app_state.redis.hget(meta_key, "user_id")
        if not user_in_redis_bytes:
            logger.error(f"Stream: user_id khÃ´ng cÃ³ trong metadata cá»§a chat {chat_id}.")
            error_payload = {"error": "Chat metadata corrupted."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        user_in_redis = user_in_redis_bytes.decode()
        if user_in_redis != user_email:
            logger.warning(f"Stream: User {user_email} khÃ´ng Ä‘Æ°á»£c phÃ©p truy cáº­p chat {chat_id}.")
            error_payload = {"error": "Unauthorized to access this chat."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        # --- 2. Tiá»n xá»­ lÃ½ cÃ¢u há»i (TÆ°Æ¡ng tá»±) ---
        cleaned_question = minimal_preprocess_for_llm(question_content)

        initial_processing_done_time = time.time()
        logger.info(f"Stream: Initial processing for {chat_id} took {initial_processing_done_time - start_time_total:.2f}s")

        # --- 3. Kiá»ƒm tra tá»« Ä‘iá»ƒn thuáº­t ngá»¯ (náº¿u cÃ³, vÃ  nÃ³ nhanh) ---
        if hasattr(app_state, 'dict') and app_state.dict:
            term_result = search_term_in_dictionary(cleaned_question, app_state.dict)
            if term_result:
                answer_def = term_result.get("definition", "KhÃ´ng thá»ƒ tÃ¬m tháº¥y Ä‘á»‹nh nghÄ©a.")
                assistant_response_time_dict = datetime.now(timezone.utc)
                full_answer_for_saving = answer_def # GÃ¡n cho lÆ°u trá»¯

                # Stream toÃ n bá»™ Ä‘á»‹nh nghÄ©a nhÆ° má»™t chunk
                data_payload = {"token": answer_def, "is_final": True, "source": "dictionary"}
                yield f"data: {json.dumps(data_payload)}\n\n"
                # CÃ³ thá»ƒ gá»­i event káº¿t thÃºc riÃªng
                yield f"event: end_stream\ndata: {{}}\n\n" # Event káº¿t thÃºc tÃ¹y chá»‰nh

                # LÆ°u vÃ o Redis vÃ  MongoDB (sau khi stream)
                await save_chat_to_redis(
                    app_state.redis, chat_id, question_content, full_answer_for_saving, current_utc_time, assistant_response_time_dict
                )
                asyncio.create_task(save_chat_to_mongo( # Cháº¡y ná»n
                    conversations_collection, chat_id, user_email, question_content, full_answer_for_saving, current_utc_time, assistant_response_time_dict
                ))
                processing_time_dict = round(time.time() - start_time_total, 2)
                logger.info(f"Stream: Dictionary answer for {chat_id} sent in {processing_time_dict:.2f}s.")
                return # Káº¿t thÃºc generator á»Ÿ Ä‘Ã¢y

        if not app_state.qa_chain: # qa_chain pháº£i há»— trá»£ streaming
            logger.error("Stream: QA Chain chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o hoáº·c khÃ´ng há»— trá»£ streaming.")
            error_payload = {"error": "Service Unavailable: QA Chain not ready for streaming."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        # --- 4. Láº¥y lá»‹ch sá»­ chat cho Langchain Chain (TÆ°Æ¡ng tá»±) ---
        try:
            langchain_chat_history = await  get_langchain_chat_history(app_state, chat_id)
            input_data_for_chain = {
                "chat_history": langchain_chat_history.messages,
                "input": cleaned_question
            }
        except Exception as e:
            logger.error(f"Stream: Lá»—i khi chuáº©n bá»‹ chat history (chat_id: {chat_id}): {e}", exc_info=True)
            error_payload = {"error": "Error processing chat history."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        # --- 5. Gá»i QA Chain vá»›i streaming ---

        if not (hasattr(app_state.qa_chain, 'astream') or hasattr(app_state.qa_chain, 'stream')):
            logger.error(f"Stream: QA Chain (type: {type(app_state.qa_chain)}) khÃ´ng cÃ³ phÆ°Æ¡ng thá»©c astream hoáº·c stream.")
            error_payload = {"error": "QA Chain does not support streaming."}
            yield f"event: error\ndata: {json.dumps(error_payload)}\n\n"
            return

        chain_stream_method = app_state.qa_chain.astream if hasattr(app_state.qa_chain, 'astream') else app_state.qa_chain.stream

        logger.info(f"Stream: Invoking chain stream for {chat_id}...")
        stream_start_time = time.time()
        chunk_count = 0
        sources_streamed = False # Cá» Ä‘á»ƒ chá»‰ stream sources má»™t láº§n

        async for chunk in chain_stream_method(input_data_for_chain):

            token = ""
            current_sources = None

            if isinstance(chunk, str):
                token = chunk
            elif hasattr(chunk, 'content'): # Giá»‘ng AIMessageChunk
                token = chunk.content
            elif isinstance(chunk, dict):
                token = chunk.get("answer") or chunk.get("token") or chunk.get("content") or ""
                # Kiá»ƒm tra sources náº¿u chunk lÃ  dict vÃ  chÆ°a stream sources
                if not sources_streamed and "source" in chunk:
                    current_sources = chunk["source"]

            if token:
                full_answer_for_saving += token
                data_payload = {"token": token, "is_final": False}
                yield f"data: {json.dumps(data_payload)}\n\n"
                chunk_count += 1

            # Stream sources náº¿u cÃ³ vÃ  chÆ°a Ä‘Æ°á»£c stream
            if current_sources and not sources_streamed:
                sources_list = []
                for doc in current_sources:
                    if hasattr(doc, 'metadata') and hasattr(doc, 'page_content'):
                        sources_list.append(SourceDocument(
                            source=doc.metadata.get('source', 'N/A'),
                            page_content_preview=doc.page_content[:200] + "..."
                        ).dict()) # Chuyá»ƒn sang dict Ä‘á»ƒ JSON serialize
                if sources_list:
                    source_payload = {"sources": sources_list}
                    yield f"event: sources\ndata: {json.dumps(source_payload)}\n\n" # Event riÃªng cho sources
                    sources_streamed = True # ÄÃ¡nh dáº¥u Ä‘Ã£ stream


        stream_end_time = time.time()
        logger.info(f"Stream: Chain streaming for {chat_id} completed in {stream_end_time - stream_start_time:.2f}s with {chunk_count} chunks.")

        # --- Gá»­i event káº¿t thÃºc stream ---
        # Frontend cÃ³ thá»ƒ dÃ¹ng event nÃ y Ä‘á»ƒ biáº¿t stream Ä‘Ã£ hoÃ n táº¥t.
        # Hoáº·c, frontend cÃ³ thá»ƒ dá»±a vÃ o má»™t chunk Ä‘áº·c biá»‡t nhÆ° `{"is_final": true}`
        # Hoáº·c Ä‘Æ¡n giáº£n lÃ  khi `EventSource.onmessage` khÃ´ng nháº­n Ä‘Æ°á»£c gÃ¬ ná»¯a sau má»™t timeout.
        yield f"event: end_stream\ndata: {{ \"message\": \"Stream ended\" }}\n\n"


        # --- 6. LÆ°u tin nháº¯n hoÃ n chá»‰nh (sau khi stream xong) ---
        assistant_response_time = datetime.now(timezone.utc)
        if not full_answer_for_saving.strip() and chunk_count == 0: # Náº¿u khÃ´ng cÃ³ token nÃ o Ä‘Æ°á»£c stream
            full_answer_for_saving = "TÃ´i khÃ´ng tÃ¬m tháº¥y cÃ¢u tráº£ lá»i phÃ¹ há»£p."
            # Stream cÃ¢u tráº£ lá»i máº·c Ä‘á»‹nh nÃ y náº¿u chÆ°a cÃ³ gÃ¬
            data_payload = {"token": full_answer_for_saving, "is_final": True}
            yield f"data: {json.dumps(data_payload)}\n\n"
            yield f"event: end_stream\ndata: {{ \"message\": \"Stream ended with default message\" }}\n\n"


        logger.info(f"Stream: Full answer for {chat_id} to be saved: {full_answer_for_saving[:100]}...")
        await save_chat_to_redis(
            app_state.redis, chat_id, question_content, full_answer_for_saving, current_utc_time, assistant_response_time
        )
        # Cháº¡y lÆ°u MongoDB ngáº§m Ä‘á»ƒ khÃ´ng block
        asyncio.create_task(save_chat_to_mongo(
            conversations_collection, chat_id, user_email, question_content, full_answer_for_saving, current_utc_time, assistant_response_time
        ))

        # Cáº­p nháº­t Langchain history (náº¿u chain memory khÃ´ng tá»± lÃ m)
        # await langchain_chat_history.aadd_user_message(question_for_chain)
        # await langchain_chat_history.aadd_ai_message(full_answer_for_saving)


    except HTTPException as e: # Báº¯t HTTPException Ä‘Ã£ Ä‘Æ°á»£c raise tá»« cÃ¡c hÃ m con
        logger.error(f"Stream: HTTPException for chat_id {chat_id}: {e.detail}", exc_info=True)
        error_payload = {"error": e.detail, "status_code": e.status_code}
        yield f"event: error_stream\ndata: {json.dumps(error_payload)}\n\n"
    except Exception as e:
        logger.error(f"Stream: Unhandled exception for chat_id {chat_id}: {e}", exc_info=True)
        error_payload = {"error": "An unexpected server error occurred during streaming."}
        yield f"event: error_stream\ndata: {json.dumps(error_payload)}\n\n"
    finally:
        # Äáº£m báº£o generator káº¿t thÃºc Ä‘Ãºng cÃ¡ch.
        # EventSource trÃªn client sáº½ tá»± Ä‘á»™ng Ä‘Ã³ng khi generator káº¿t thÃºc.
        # Hoáº·c báº¡n cÃ³ thá»ƒ gá»­i má»™t tÃ­n hiá»‡u Ä‘Ã³ng rÃµ rÃ ng náº¿u cáº§n.
        # yield "event: close\ndata: Connection closed by server\n\n" # KhÃ´ng chuáº©n SSE, nhÆ°ng má»™t sá»‘ client cÃ³ thá»ƒ hiá»ƒu
        logger.info(f"Stream: Generator for chat_id {chat_id} finished. Total time: {time.time() - start_time_total:.2f}s")


# Sá»­ dá»¥ng GET cho EventSource theo chuáº©n, truyá»n params qua query string
# EventSource chá»‰ há»— trá»£ GET. Náº¿u báº¡n Báº®T BUá»˜C pháº£i dÃ¹ng POST (vÃ­ dá»¥, cÃ¢u há»i quÃ¡ dÃ i cho URL),
# báº¡n sáº½ cáº§n má»™t giáº£i phÃ¡p phá»©c táº¡p hÆ¡n, khÃ´ng dÃ¹ng EventSource trá»±c tiáº¿p trÃªn client
# mÃ  dÃ¹ng fetch API vá»›i ReadableStream vÃ  POST.


#helper

from typing import List, Optional,Any

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
async def prepare_chat_history_optimized(
    redis:Any,
    chat_id: str,
    max_messages: int = 10,  # Sá»‘ lÆ°á»£ng cáº·p tin nháº¯n (user+AI) tá»‘i Ä‘a Ä‘á»ƒ láº¥y
    max_tokens: Optional[int] = None, # (TÃ¹y chá»n nÃ¢ng cao) Giá»›i háº¡n token
    tokenizer: Optional[Any] = None # (TÃ¹y chá»n nÃ¢ng cao) Tokenizer Ä‘á»ƒ Ä‘áº¿m token
) -> List[BaseMessage]:
    """
    Cáº¢I TIáº¾N: Láº¥y N tin nháº¯n gáº§n nháº¥t tá»« Redis Ä‘á»ƒ lÃ m lá»‹ch sá»­ chat.
    - Hiá»‡u quáº£ hÆ¡n báº±ng cÃ¡ch chá»‰ láº¥y má»™t pháº§n lá»‹ch sá»­.
    - An toÃ n hÆ¡n báº±ng cÃ¡ch kiá»ƒm soÃ¡t Ä‘á»™ dÃ i ngá»¯ cáº£nh.

    Args:
        redis: Client Redis báº¥t Ä‘á»“ng bá»™.
        chat_id: ID cá»§a cuá»™c trÃ² chuyá»‡n.
        max_messages: Sá»‘ lÆ°á»£ng tin nháº¯n tá»‘i Ä‘a Ä‘á»ƒ láº¥y tá»« cuá»‘i (vÃ­ dá»¥: 10 tin nháº¯n gáº§n nháº¥t).
        max_tokens: (NÃ¢ng cao) Giá»›i háº¡n tá»•ng sá»‘ token cá»§a lá»‹ch sá»­.
        tokenizer: (NÃ¢ng cao) Tokenizer Ä‘á»ƒ sá»­ dá»¥ng vá»›i max_tokens.

    Returns:
        Má»™t danh sÃ¡ch cÃ¡c Ä‘á»‘i tÆ°á»£ng tin nháº¯n cá»§a LangChain (HumanMessage, AIMessage).
    """
    messages_key = f"conversation_messages:{chat_id}"

    # 1. Láº¥y N tin nháº¯n gáº§n nháº¥t tá»« Redis
    # lrange(key, -N, -1) sáº½ láº¥y N pháº§n tá»­ cuá»‘i cÃ¹ng cá»§a list.
    # Láº¥y nhiá»u hÆ¡n má»™t chÃºt Ä‘á»ƒ Ä‘áº£m báº£o cÃ³ cáº·p user/ai hoÃ n chá»‰nh.
    num_to_fetch = max_messages + 2
    try:
        # Sá»­ dá»¥ng lrange Ä‘á»ƒ láº¥y cÃ¡c tin nháº¯n gáº§n nháº¥t, hiá»‡u quáº£ hÆ¡n nhiá»u so vá»›i láº¥y táº¥t cáº£
        raw_messages_json = await redis.lrange(messages_key, -num_to_fetch, -1)
        if not raw_messages_json:
            return []
    except Exception as e:
        logger.error(f"Lá»—i khi Ä‘á»c lá»‹ch sá»­ chat tá»« Redis cho chat_id {chat_id}: {e}")
        return []

    # 2. XÃ¢y dá»±ng danh sÃ¡ch tin nháº¯n cho LangChain
    langchain_messages: List[BaseMessage] = []
    total_tokens = 0

    # Láº·p ngÆ°á»£c tá»« cuá»‘i (tin nháº¯n má»›i nháº¥t) Ä‘á»ƒ xá»­ lÃ½
    for msg_json_str in reversed(raw_messages_json):
        try:
            msg_data = json.loads(msg_json_str)
            content = msg_data.get("content", "")

            # (TÃ¹y chá»n nÃ¢ng cao) Kiá»ƒm tra giá»›i háº¡n token
            if max_tokens and tokenizer:
                num_tokens = len(tokenizer.encode(content))
                if total_tokens + num_tokens > max_tokens:
                    logger.warning(f"ÄÃ£ Ä‘áº¡t giá»›i háº¡n token ({max_tokens}) cho lá»‹ch sá»­ chat. Dá»«ng láº¡i.")
                    break # Dá»«ng thÃªm tin nháº¯n
                total_tokens += num_tokens

            # Táº¡o Ä‘á»‘i tÆ°á»£ng tin nháº¯n phÃ¹ há»£p
            if msg_data.get("role") == "user":
                langchain_messages.append(HumanMessage(content=content))
            elif msg_data.get("role") == "assistant":
                langchain_messages.append(AIMessage(content=content))

        except (json.JSONDecodeError, KeyError) as e:
            logger.warning(f"Lá»—i khi parse tin nháº¯n tá»« Redis: {e}. Bá» qua tin nháº¯n nÃ y.")
            continue

    # 3. Äáº£o ngÆ°á»£c láº¡i danh sÃ¡ch Ä‘á»ƒ cÃ³ Ä‘Ãºng thá»© tá»± (cÅ© -> má»›i)
    langchain_messages.reverse()

    # Cáº¯t láº¡i theo max_messages cuá»‘i cÃ¹ng Ä‘á»ƒ Ä‘áº£m báº£o sá»‘ lÆ°á»£ng chÃ­nh xÃ¡c
    return langchain_messages[-max_messages:]

def format_chat_history_for_prompt(chat_history: List[BaseMessage]) -> str:
    """
    Chuyá»ƒn Ä‘á»•i danh sÃ¡ch Ä‘á»‘i tÆ°á»£ng tin nháº¯n thÃ nh má»™t chuá»—i vÄƒn báº£n duy nháº¥t.
    """
    if not chat_history:
        return "KhÃ´ng cÃ³ lá»‹ch sá»­ trÃ² chuyá»‡n."

    formatted_history = []
    for message in chat_history:
        role = "NgÆ°á»i dÃ¹ng" if isinstance(message, HumanMessage) else "Trá»£ lÃ½"
        formatted_history.append(f"{role}: {message.content}")

    return "\n".join(formatted_history)